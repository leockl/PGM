{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import Parallel, delayed\n",
    "from scipy import linalg\n",
    "\n",
    "class PGMHQC_fast(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"The Pretty Good Measurement (PGM) - Helstrom Quantum Centroid (HQC) classifier is a \n",
    "    quantum-inspired supervised classification approach for data with multiple classes.\n",
    "                         \n",
    "    Parameters\n",
    "    ----------\n",
    "    rescale : int or float, default = 1\n",
    "        The dataset rescaling factor. A parameter used for rescaling the dataset. \n",
    "    encoding : str, default = 'amplit'\n",
    "        The encoding method used to encode vectors into quantum densities. Possible values:\n",
    "        'amplit', 'stereo'. 'amplit' means using the amplitude encoding method. 'stereo' means \n",
    "        using the inverse of the standard stereographic projection encoding method. Default set \n",
    "        to 'amplit'.\n",
    "    n_copies : int, default = 1\n",
    "        The number of copies to take for each quantum density. This is equivalent to taking \n",
    "        the n-fold Kronecker tensor product for each quantum density.\n",
    "    measure : str, default = 'pgm'\n",
    "        The measurement used to distinguish between quantum states. Possible values: 'pgm', \n",
    "        'hels'. The value 'pgm' stands for \"Pretty Good Measurement\", 'hels' stands for \n",
    "        \"Helstrom measurement\" (applicable only for binary classification). Default set to \n",
    "        'pgm'.\n",
    "    class_wgt : str, default = None        \n",
    "        Applicable only when \"Helstrom measurement\" is selected. This is the class weights \n",
    "        assigned to the Quantum Helstrom observable terms. Possible values: 'equi', 'weighted', \n",
    "        None. 'equi' means assigning equal weights of 1/2 (equiprobable) to the two terms in \n",
    "        the Quantum Helstrom observable. 'weighted' means assigning weights equal to the \n",
    "        proportion of the number of rows in each class to the two terms in the Quantum Helstrom \n",
    "        observable. When using \"Pretty Good Measurement\", specify class_wgt = None. Default set \n",
    "        to None.\n",
    "    n_jobs : int, default = None\n",
    "        The number of CPU cores used when parallelizing. If -1 all CPUs are used. If 1 is given, \n",
    "        no parallel computing code is used at all. For n_jobs below -1, (n_cpus + 1 + n_jobs) \n",
    "        are used. Thus for n_jobs = -2, all CPUs but one are used. None is a marker for ‘unset’ \n",
    "        that will be interpreted as n_jobs = 1.\n",
    "    n_splits : int, default = 1\n",
    "        The number of subset splits performed on the input dataset row-wise and on the number \n",
    "        of eigenvalues/eigenvectors of the Quantum Helstrom observable for optimal speed \n",
    "        performance. If 1 is given, no splits are performed. For optimal speed, recommend using \n",
    "        n_splits = int(numpy.ceil(number of CPU cores used/number of classes)). If memory blow-out \n",
    "        occurs, reduce n_splits. When n_splits = 1 and memory blow-out still occurs, reduce n_jobs.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : ndarray, shape (n_classes,)\n",
    "        Sorted classes.\n",
    "    qcentroids_ : ndarray, shape (n_classes, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Quantum Centroids for each class.\n",
    "    pgms_ : list, shape (n_classes, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Pretty Good Measurement.\n",
    "    hels_obs_ : ndarray, shape ((n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Quantum Helstrom observable.\n",
    "    proj_sums_ : list, shape (n_classes, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Sum of the projectors of the Quantum Helstrom observable's unit eigenvectors, which has\n",
    "        corresponding positive and negative eigenvalues respectively.\n",
    "    hels_bound_ : float\n",
    "        Helstrom bound is the upper bound of the probability that one can correctly \n",
    "        discriminate whether a quantum density is of which of the two binary quantum density \n",
    "        pattern.          \n",
    "    \"\"\"\n",
    "    # Initialize model hyperparameters\n",
    "    def __init__(self, \n",
    "                 rescale = 1,\n",
    "                 encoding = 'amplit',\n",
    "                 n_copies = 1, \n",
    "                 measure = 'pgm',\n",
    "                 class_wgt = None, \n",
    "                 n_jobs = None, \n",
    "                 n_splits = 1):\n",
    "        self.rescale = rescale\n",
    "        self.encoding = encoding\n",
    "        self.n_copies = n_copies\n",
    "        self.measure = measure\n",
    "        self.class_wgt = class_wgt\n",
    "        self.n_jobs = n_jobs\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "    \n",
    "    # Function for kronecker tensor product with broadcasting, set as global function\n",
    "    global kronecker\n",
    "    def kronecker(A, B):\n",
    "        return np.einsum('nab,ncd->nacbd', A, B).reshape(A.shape[0],\n",
    "                                                         A.shape[1]*B.shape[1],\n",
    "                                                         A.shape[2]*B.shape[2])\n",
    "    \n",
    "    \n",
    "    # Function for fit\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Perform PGM-HQC classification with the amplitude and inverse of the standard \n",
    "        stereographic projection encoding methods, with the option to rescale the dataset prior \n",
    "        to encoding.\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples. An array of int or float.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The training input binary target values. An array of str, int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # Check data in X and y as required by scikit-learn v0.25\n",
    "        X, y = self._validate_data(X, y, reset = True)\n",
    "        \n",
    "        # Ensure target y is of non-regression type  \n",
    "        # Added as required by sklearn check_estimator\n",
    "        check_classification_targets(y)\n",
    "    \n",
    "        # Store classes and encode y into class indexes\n",
    "        self.classes_, y_class_index = np.unique(y, return_inverse = True)\n",
    "                \n",
    "        # Number of classes, set as global variable\n",
    "        global num_classes\n",
    "        num_classes = len(self.classes_)\n",
    "        \n",
    "        # Raise error when there are more than 2 classes and Helstrom measurement is specified\n",
    "        if num_classes > 2 and self.measure == 'hels':\n",
    "            raise ValueError('Helstrom measurement can be applied for binary classification only')\n",
    "        else:\n",
    "            # Cast X to float to ensure all following calculations below are done in float  \n",
    "            # rather than integer\n",
    "            X = X.astype(float)\n",
    "        \n",
    "            # Rescale X\n",
    "            X = self.rescale*X\n",
    "        \n",
    "            # Calculate sum of squares of each row (sample) in X\n",
    "            X_sq_sum = (X**2).sum(axis = 1)\n",
    "        \n",
    "            # Number of rows in X\n",
    "            m = X.shape[0]\n",
    "        \n",
    "            # Number of columns in X\n",
    "            n = X.shape[1]\n",
    "        \n",
    "            # Calculate X' using amplitude or inverse of the standard stereographic projection \n",
    "            # encoding method\n",
    "            if self.encoding == 'amplit':\n",
    "                X_prime = normalize(np.concatenate((X, np.ones(m).reshape(-1, 1)), axis = 1))\n",
    "            elif self.encoding == 'stereo':\n",
    "                X_prime = (1/(X_sq_sum + 1)).reshape(-1, 1) \\\n",
    "                          *(np.concatenate((2*X, (X_sq_sum - 1).reshape(-1, 1)), axis = 1))\n",
    "            else:\n",
    "                raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n",
    "        \n",
    "            # Number of columns in X', set as global variable\n",
    "            global n_prime\n",
    "            n_prime = n + 1\n",
    "        \n",
    "            # Function to calculate number of rows (samples) and Quantum Centroids for each class\n",
    "            def qcentroids_terms_func(i):\n",
    "                # Determine rows (samples) in X' belonging to each class\n",
    "                X_prime_class = X_prime[y_class_index == i]\n",
    "            \n",
    "                # Number of rows (samples) in X' belonging to either class\n",
    "                m_class = X_prime_class.shape[0]\n",
    "            \n",
    "                # Split X' belonging to each class into n_splits subsets, row-wise\n",
    "                X_prime_class_split = np.array_split(X_prime_class,\n",
    "                                                     indices_or_sections = self.n_splits,\n",
    "                                                     axis = 0)\n",
    "            \n",
    "                # Function to calculate the Quantum Centroids for each class, per subset split\n",
    "                def X_prime_class_split_func(j):\n",
    "                    # Counter for j-th split of X'\n",
    "                    X_prime_class_split_jth = X_prime_class_split[j]\n",
    "                \n",
    "                    # Number of rows (samples) in j-th split of X'\n",
    "                    m_class_split = X_prime_class_split_jth.shape[0]\n",
    "                \n",
    "                    # Encode vectors into quantum densities\n",
    "                    density_split = np.matmul(X_prime_class_split_jth.reshape(m_class_split, \n",
    "                                                                              n_prime, 1),\n",
    "                                              X_prime_class_split_jth.reshape(m_class_split, \n",
    "                                                                              1, n_prime))\n",
    "                                        \n",
    "                    # Calculate n-fold Kronecker tensor product\n",
    "                    if self.n_copies == 1:\n",
    "                        density_split = density_split\n",
    "                    else:\n",
    "                        density_split_copy = density_split\n",
    "                        for u in range(self.n_copies - 1):\n",
    "                            density_split = kronecker(density_split, density_split_copy)\n",
    "                \n",
    "                    # Calculate sum of quantum densities\n",
    "                    density_split_sum = density_split.sum(axis = 0)\n",
    "                \n",
    "                    # Calculate Quantum Centroid for each class, per subset split\n",
    "                    # Added ZeroDivisionError as required by scikit-learn check_estimator()\n",
    "                    try:\n",
    "                        qcentroid = (1/m_class)*density_split_sum\n",
    "                    except ZeroDivisionError:\n",
    "                        qcentroid = 0\n",
    "                    return qcentroid\n",
    "                return m_class, np.sum(Parallel(n_jobs = self.n_jobs)(delayed(X_prime_class_split_func)(j) \n",
    "                                                                      for j in range(self.n_splits)), axis = 0)\n",
    "        \n",
    "            # Calculate number of rows (samples) and Quantum Centroids for each class\n",
    "            # Added dtype = object as required by NumPy v19.0 when creating ndarray from ragged nested sequences\n",
    "            qcentroids_terms = np.array(Parallel(n_jobs = self.n_jobs)(delayed(qcentroids_terms_func)(i) \n",
    "                                                                       for i in range(num_classes)), dtype = object)\n",
    "        \n",
    "            # Determine Quantum Centroids\n",
    "            self.qcentroids_ = qcentroids_terms[:, 1]\n",
    "        \n",
    "            # When Pretty Good Measurement is specified\n",
    "            if self.measure == 'pgm':\n",
    "                if self.class_wgt == None:\n",
    "                    # Calculate R\n",
    "                    R = np.sum(self.qcentroids_, axis = 0)\n",
    "            \n",
    "                    # Calculate square root of the pseudo inverse of R, and remove complex part of the matrix\n",
    "                    # created due to numerical precision/rounding issues in machine language\n",
    "                    sqrt_pinv_R = np.real(linalg.sqrtm(np.linalg.pinv(R, hermitian = True)))\n",
    "                    \n",
    "                    # Calculate kernel of R\n",
    "                    ker_R = linalg.null_space(R)\n",
    "                    \n",
    "                    # Calculate projector of kernel of R\n",
    "                    proj_ker_R = np.dot(ker_R, ker_R.T)\n",
    "                    \n",
    "                    # Function to calculate Pretty Good Measurement\n",
    "                    def pgm_func(a):\n",
    "                        return np.linalg.multi_dot([sqrt_pinv_R, self.qcentroids_[a], sqrt_pinv_R]) \\\n",
    "                               + (1/num_classes)*proj_ker_R\n",
    "            \n",
    "                    # Calculate Pretty Good Measurement\n",
    "                    self.pgms_ = Parallel(n_jobs = self.n_jobs)(delayed(pgm_func)(a) \n",
    "                                                                for a in range(num_classes))\n",
    "                else:\n",
    "                    raise ValueError('when using \"pgm\" measure, class_wgt should be None')\n",
    "            # When Helstrom measurement is specified\n",
    "            elif self.measure == 'hels':\n",
    "                # Calculate quantum Helstrom observable\n",
    "                if self.class_wgt == 'equi':\n",
    "                    self.hels_obs_ = 0.5*(self.qcentroids_[0] - self.qcentroids_[1])\n",
    "                elif self.class_wgt == 'weighted':\n",
    "                    self.hels_obs_ = (qcentroids_terms[0, 0]/m)*self.qcentroids_[0] \\\n",
    "                                     - (qcentroids_terms[1, 0]/m)*self.qcentroids_[1]\n",
    "                else:\n",
    "                    raise ValueError('when using \"hels\" measure, class_wgt should be \"equi\" or \"weighted\"')\n",
    "            \n",
    "                # Number of rows/columns in density matrix, set as global variable\n",
    "                global density_nrow_ncol\n",
    "                density_nrow_ncol = self.hels_obs_.shape[0]\n",
    "            \n",
    "                # Calculate eigenvalues w and unit eigenvectors v of the quantum Helstrom observable\n",
    "                w, v = np.linalg.eigh(self.hels_obs_)\n",
    "                \n",
    "                # Length of w\n",
    "                len_w = len(w)\n",
    "                \n",
    "                # Initialize array eigval_class\n",
    "                eigval_class = np.empty_like(w)\n",
    "                for b in range(len_w):\n",
    "                    # Create an array of 0s and 1s to indicate positive and negative eigenvalues\n",
    "                    # respectively\n",
    "                    if w[b] > 0:\n",
    "                        eigval_class[b] = 0\n",
    "                    else:\n",
    "                        eigval_class[b] = 1\n",
    "                        \n",
    "                # Transpose matrix v containing unit eigenvectors to row-wise\n",
    "                eigvec = v.T\n",
    "                \n",
    "                # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "                # eigenvalues respectively\n",
    "                def sum_proj_func(c):\n",
    "                    # Determine unit eigenvectors belonging to positive and negative eigenvalues \n",
    "                    # respectively\n",
    "                    eigvec_class = eigvec[eigval_class == c]\n",
    "                    \n",
    "                    # Split unit eigenvectors into n_splits subsets\n",
    "                    eigvec_class_split = np.array_split(eigvec_class,\n",
    "                                                        indices_or_sections = self.n_splits,\n",
    "                                                        axis = 0)\n",
    "                    \n",
    "                    # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "                    # eigenvalues respectively, per subset split\n",
    "                    def eigvec_class_split_func(d):\n",
    "                        # Counter for d-th split of eigvec_class_split\n",
    "                        eigvec_class_split_dth = eigvec_class_split[d]\n",
    "                    \n",
    "                        # Number of rows (samples) in d-th split of eigvec_class_split\n",
    "                        m_eigvec_class_split = eigvec_class_split_dth.shape[0]\n",
    "                    \n",
    "                        # Calculate projectors corresponding to positive and negative eigenvalues\n",
    "                        # respectively, per subset split\n",
    "                        proj_split = np.matmul(eigvec_class_split_dth.reshape(m_eigvec_class_split,\n",
    "                                                                              density_nrow_ncol, 1),\n",
    "                                               eigvec_class_split_dth.reshape(m_eigvec_class_split,\n",
    "                                                                              1, density_nrow_ncol))\n",
    "\n",
    "                        # Calculate sum of projectors\n",
    "                        proj_split_sum = proj_split.sum(axis = 0)\n",
    "                        return proj_split_sum\n",
    "                    return np.sum(Parallel(n_jobs = self.n_jobs)(delayed(eigvec_class_split_func)(d) \n",
    "                                                                 for d in range(self.n_splits)), axis = 0)\n",
    "                \n",
    "                # Calculate sum of the projectors corresponding to positive and negative eigenvalues\n",
    "                # respectively\n",
    "                self.proj_sums_ = Parallel(n_jobs = self.n_jobs)(delayed(sum_proj_func)(c) \n",
    "                                                                 for c in range(num_classes))\n",
    "                \n",
    "                # Calculate Helstrom bound\n",
    "                self.hels_bound_ = (qcentroids_terms[0, 0]/m)*np.einsum('ij,ji->', self.qcentroids_[0],                                                                      \n",
    "                                                                          self.proj_sums_[0]) \\\n",
    "                                   + (qcentroids_terms[1, 0]/m)*np.einsum('ij,ji->', self.qcentroids_[1],\n",
    "                                                                            self.proj_sums_[1])\n",
    "            # When Pretty Good Measurement or Helstrom measurement is misspecified\n",
    "            else:\n",
    "                raise ValueError('measure should be \"pgm\" or \"hels\"')\n",
    "        return self             \n",
    "\n",
    "    \n",
    "    # Function for predict_proba\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Performs PMG-HQC classification on X and returns the trace of the dot product of the \n",
    "        densities and the POV (positive operator-valued) measure, i.e. the class probabilities.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.       \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        trace_matrix : ndarray, shape (n_samples, n_classes)\n",
    "            Each column corresponds to the trace of the dot product of the densities and the POV \n",
    "            (positive operator-valued) measure for each class, i.e. each column corresponds to the \n",
    "            class probabilities. An array of float.\n",
    "        \"\"\"\n",
    "        # Check if fit had been called\n",
    "        if self.measure == 'pgm':\n",
    "            check_is_fitted(self, ['pgms_'])\n",
    "        else:\n",
    "            check_is_fitted(self, ['proj_sums_'])\n",
    "\n",
    "        # Check data in X as required by scikit-learn v0.25\n",
    "        X = self._validate_data(X, reset = False)\n",
    "        \n",
    "        # Cast X to float to ensure all following calculations below are done in float \n",
    "        # rather than integer\n",
    "        X = X.astype(float)        \n",
    "        \n",
    "        # Rescale X\n",
    "        X = self.rescale*X        \n",
    "        \n",
    "        # Calculate sum of squares of each row (sample) in X\n",
    "        X_sq_sum = (X**2).sum(axis = 1)\n",
    "        \n",
    "        # Number of rows in X\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Number of columns in X\n",
    "        n = X.shape[1]\n",
    "\n",
    "        # Calculate X' using amplitude or inverse of the standard stereographic projection \n",
    "        # encoding method\n",
    "        if self.encoding == 'amplit':\n",
    "            X_prime = normalize(np.concatenate((X, np.ones(m).reshape(-1, 1)), axis = 1))\n",
    "        elif self.encoding == 'stereo':\n",
    "            X_prime = (1/(X_sq_sum + 1)).reshape(-1, 1) \\\n",
    "                      *(np.concatenate((2*X, (X_sq_sum - 1).reshape(-1, 1)), axis = 1))\n",
    "        else:\n",
    "            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n",
    "               \n",
    "        # Function to calculate trace values for each class\n",
    "        def trace_func(i):\n",
    "            # Split X' into n_splits subsets, row-wise\n",
    "            X_prime_split = np.array_split(X_prime, \n",
    "                                           indices_or_sections = self.n_splits, \n",
    "                                           axis = 0)\n",
    "            \n",
    "            # Function to calculate trace values for each class, per subset split\n",
    "            def trace_split_func(j):\n",
    "                # Counter for j-th split X'\n",
    "                X_prime_split_jth = X_prime_split[j]\n",
    "                \n",
    "                # Number of rows (samples) in j-th split X'\n",
    "                X_prime_split_m = X_prime_split_jth.shape[0]\n",
    "                \n",
    "                # Encode vectors into quantum densities\n",
    "                density_chunk = np.matmul(X_prime_split_jth.reshape(X_prime_split_m, n_prime, 1),\n",
    "                                          X_prime_split_jth.reshape(X_prime_split_m, 1, n_prime))\n",
    "                \n",
    "                # Calculate n-fold Kronecker tensor product\n",
    "                if self.n_copies == 1:\n",
    "                    density_chunk = density_chunk\n",
    "                else:\n",
    "                    density_chunk_copy = density_chunk\n",
    "                    for u in range(self.n_copies - 1):\n",
    "                        density_chunk = kronecker(density_chunk, density_chunk_copy)\n",
    "                        \n",
    "                # When Pretty Good Measurement is specified\n",
    "                if self.measure == 'pgm':\n",
    "                    # Calculate trace of the dot product of density of each row and Pretty Good \n",
    "                    # Measurement\n",
    "                    trace_class_split = np.einsum('bij,ji->b', density_chunk, self.pgms_[i])\n",
    "                # When Helstrom measurement is specified\n",
    "                else:               \n",
    "                    # Calculate trace of the dot product of density of each row and sum of \n",
    "                    # projectors with corresponding positive and negative eigenvalues respectively\n",
    "                    trace_class_split = np.einsum('bij,ji->b', density_chunk, self.proj_sums_[i])\n",
    "                return trace_class_split\n",
    "            \n",
    "            # Calculate trace values for each class, per subset split\n",
    "            trace_class = Parallel(n_jobs = self.n_jobs)(delayed(trace_split_func)(j) \n",
    "                                                         for j in range(self.n_splits))\n",
    "            return np.concatenate(trace_class, axis = 0)\n",
    "        \n",
    "        # Calculate trace values for each class\n",
    "        trace_matrix = np.transpose(Parallel(n_jobs = self.n_jobs)(delayed(trace_func)(i) \n",
    "                                                                   for i in range(num_classes)))\n",
    "        return trace_matrix\n",
    "        \n",
    "    \n",
    "    # Function for predict\n",
    "    def predict(self, X):\n",
    "        \"\"\"Performs PGM-HQC classification on X and returns the classes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self.classes_[predict_trace_index] : ndarray, shape (n_samples,)\n",
    "            The predicted classes. An array of str, int or float.\n",
    "        \"\"\"\n",
    "        # Determine column index with the higher trace value in trace_matrix\n",
    "        # If columns have the same trace value, returns column with the smallest column index value\n",
    "        predict_trace_index = np.argmax(self.predict_proba(X), axis = 1)\n",
    "        # Returns the predicted classes\n",
    "        return self.classes_[predict_trace_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris dataset (5 features, 150 rows)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('iris.tsv', sep='\\t')\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if class imbalance\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2713954 , 0.35128921, 0.37731539, 1.        ],\n",
       "       [0.22444864, 0.36579336, 0.409758  , 1.        ],\n",
       "       [0.57218509, 0.26031789, 0.16749703, 1.        ],\n",
       "       [0.2334315 , 0.35231182, 0.41425668, 1.        ],\n",
       "       [0.21783856, 0.35878154, 0.4233799 , 1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# Check F1 score for various n_copies values\n",
    "model = PGMHQC_fast(rescale=0.5, n_copies=1, encoding='stereo', measure='pgm', class_wgt=None, n_jobs=16, n_splits=6).fit(X_train, y_train)\n",
    "\n",
    "# Check trace values sum to 1 for first 5 rows\n",
    "np.concatenate([model.predict_proba(X_test), np.sum(model.predict_proba(X_test), axis=1).reshape(-1,1)], axis=1)[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8940170940170941"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check F1 score for various n_copies values\n",
    "model = PGMHQC_fast(rescale=0.5, n_copies=1, encoding='stereo', measure='pgm', class_wgt=None, n_jobs=16, n_splits=6).fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8940170940170941"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check F1 score for various n_copies values\n",
    "model = PGMHQC_fast(rescale=0.5, n_copies=2, encoding='stereo', measure='pgm', class_wgt=None, n_jobs=16, n_splits=6).fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8940170940170941"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check F1 score for various n_copies values\n",
    "model = PGMHQC_fast(rescale=0.5, n_copies=3, encoding='stereo', measure='pgm', class_wgt=None, n_jobs=16, n_splits=6).fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8940170940170941"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check F1 score for various n_copies values\n",
    "model = PGMHQC_fast(rescale=0.5, n_copies=4, encoding='stereo', measure='pgm', class_wgt=None, n_jobs=16, n_splits=6).fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8940170940170941"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check F1 score for various n_copies values\n",
    "model = PGMHQC_fast(rescale=0.5, n_copies=5, encoding='stereo', measure='pgm', class_wgt=None, n_jobs=16, n_splits=6).fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 12.7 GiB for an array with shape (7, 3125, 5, 3125, 5) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 253, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 253, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-59-7645e6292074>\", line 206, in qcentroids_terms_func\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1042, in __call__\n    self.retrieve()\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in retrieve\n    self._output.extend(job.get(timeout=self.timeout))\n  File \"C:\\Users\\server\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 657, in get\n    raise self._value\n  File \"C:\\Users\\server\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 253, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 253, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-59-7645e6292074>\", line 193, in X_prime_class_split_func\n  File \"<ipython-input-59-7645e6292074>\", line 89, in kronecker\n  File \"<__array_function__ internals>\", line 6, in einsum\n  File \"C:\\Users\\server\\Anaconda3\\lib\\site-packages\\numpy\\core\\einsumfunc.py\", line 1350, in einsum\n    return c_einsum(*operands, **kwargs)\nMemoryError: Unable to allocate 12.7 GiB for an array with shape (7, 3125, 5, 3125, 5) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-56bd759a0028>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check F1 score for various n_copies values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPGMHQC_fast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_copies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'stereo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pgm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-7645e6292074>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[1;31m# Added dtype = object as required by NumPy v19.0 when creating ndarray from ragged nested sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             qcentroids_terms = np.array(Parallel(n_jobs = self.n_jobs)(delayed(qcentroids_terms_func)(i) \n\u001b[1;32m--> 211\u001b[1;33m                                                                        for i in range(num_classes)), dtype = object)\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;31m# Determine Quantum Centroids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 12.7 GiB for an array with shape (7, 3125, 5, 3125, 5) and data type float64"
     ]
    }
   ],
   "source": [
    "# Check F1 score for various n_copies values\n",
    "model = PGMHQC_fast(rescale=0.5, n_copies=6, encoding='stereo', measure='pgm', class_wgt=None, n_jobs=16, n_splits=6).fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing using scikit-learn's GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create rescale hyperparamter list [0.1, 0.5, 1, 1.5,...,10.0]\n",
    "rescale_list1 = [0.1]\n",
    "rescale_list2 = np.linspace(0.5, 10, 20).tolist()\n",
    "rescale_list1.extend(rescale_list2)\n",
    "\n",
    "param_grid = {'rescale':rescale_list1, 'n_copies':[1, 2, 3, 4], 'encoding':['amplit', 'stereo'], 'measure':['pgm'], 'class_wgt':[None]}\n",
    "models = GridSearchCV(PGMHQC_fast(n_jobs=16, n_splits=6), param_grid, scoring='f1_weighted').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best F1 score\n",
    "best_model = models.best_estimator_\n",
    "y_hat = best_model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_wgt': None,\n",
       " 'encoding': 'stereo',\n",
       " 'measure': 'pgm',\n",
       " 'n_copies': 4,\n",
       " 'rescale': 0.1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hyperparameter combination\n",
    "models.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
