{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import Parallel, delayed\n",
    "from scipy import linalg\n",
    "\n",
    "class PGMHQC_fast(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"The Pretty Good Measurement (PGM) - Helstrom Quantum Centroid (HQC) classifier is a \n",
    "    quantum-inspired supervised classification approach for data with multiple classes.\n",
    "                         \n",
    "    Parameters\n",
    "    ----------\n",
    "    rescale : int or float, default = 1\n",
    "        The dataset rescaling factor. A parameter used for rescaling the dataset. \n",
    "    encoding : str, default = 'amplit'\n",
    "        The encoding method used to encode vectors into quantum densities. Possible values:\n",
    "        'amplit', 'stereo'. 'amplit' means using the amplitude encoding method. 'stereo' means \n",
    "        using the inverse of the standard stereographic projection encoding method. Default set \n",
    "        to 'amplit'.\n",
    "    n_copies : int, default = 1\n",
    "        The number of copies to take for each quantum density. This is equivalent to taking \n",
    "        the n-fold Kronecker tensor product for each quantum density.\n",
    "    measure : str, default = 'pgm'\n",
    "        The measurement used to distinguish between quantum states. Possible values: 'pgm', \n",
    "        'hels'. The value 'pgm' stands for \"Pretty Good Measurement\", 'hels' stands for \n",
    "        \"Helstrom measurement\" (applicable only for binary classification). Default set to \n",
    "        'pgm'.\n",
    "    class_weight : str, default = None \n",
    "        Weights associated with classes. This is the class weights assigned to the quantum \n",
    "        centroids in the Pretty Good Measurement or Helstrom observable. Possible values: None,\n",
    "        'balanced'. If None given, all classes are supposed to have weight one. The 'balanced' \n",
    "        mode uses the values of y to automatically adjust weights inversely proportional to class\n",
    "        frequencies in the input data as n_samples / (n_classes * np.bincount(y)). Default set\n",
    "        to None.\n",
    "    n_jobs : int, default = None\n",
    "        The number of CPU cores used when parallelizing. If -1 all CPUs are used. If 1 is given, \n",
    "        no parallel computing code is used at all. For n_jobs below -1, (n_cpus + 1 + n_jobs) \n",
    "        are used. Thus for n_jobs = -2, all CPUs but one are used. None is a marker for ‘unset’ \n",
    "        that will be interpreted as n_jobs = 1.\n",
    "    n_splits : int, default = 1\n",
    "        The number of subset splits performed on the input dataset row-wise and on the number \n",
    "        of eigenvalues/eigenvectors of the Quantum Helstrom observable for optimal speed \n",
    "        performance. If 1 is given, no splits are performed. For optimal speed, recommend using \n",
    "        n_splits = int(numpy.ceil(number of CPU cores used/number of classes)). If memory blow-out \n",
    "        occurs, reduce n_splits. When n_splits = 1 and memory blow-out still occurs, reduce n_jobs.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : ndarray, shape (n_classes,)\n",
    "        Sorted classes.\n",
    "    qcentroids_ : ndarray, shape (n_classes, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Quantum Centroids for each class.\n",
    "    pgms_ : list, shape (n_classes, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Values for the Pretty Good Measurements. Only applicable when Pretty Good Measurement is \n",
    "        selected.\n",
    "    pgm_bound_ : float\n",
    "        Pretty Good Measurement bound is the upper bound on the probability that one can correctly\n",
    "        discriminate whether a quantum density is of which of the (multiclass) N quantum density \n",
    "        patterns. Only applicable when Pretty Good Measurement is selected.\n",
    "    proj_sums_ : list, shape (n_classes, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Sum of the projectors of the Quantum Helstrom observable's unit eigenvectors, which has\n",
    "        corresponding positive and negative eigenvalues respectively. Only applicable when Helstrom\n",
    "        Measurement is selected.\n",
    "    hels_bound_ : float\n",
    "        Helstrom bound is the upper bound on the probability that one can correctly \n",
    "        discriminate whether a quantum density is of which of the two binary quantum density \n",
    "        patterns. Only applicable when Helstrom Measurement is selected.         \n",
    "    \"\"\"\n",
    "    # Initialize model hyperparameters\n",
    "    def __init__(self, \n",
    "                 rescale = 1,\n",
    "                 encoding = 'amplit',\n",
    "                 n_copies = 1, \n",
    "                 measure = 'pgm',\n",
    "                 class_weight = None, \n",
    "                 n_jobs = None, \n",
    "                 n_splits = 1):\n",
    "        self.rescale = rescale\n",
    "        self.encoding = encoding\n",
    "        self.n_copies = n_copies\n",
    "        self.measure = measure\n",
    "        self.class_weight = class_weight\n",
    "        self.n_jobs = n_jobs\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "\n",
    "    # Function for X_prime, set as global function\n",
    "    global X_prime_func\n",
    "    def X_prime_func(self, X, m):\n",
    "        # Cast X to float to ensure all following calculations below are done in float\n",
    "        # rather than integer\n",
    "        X = X.astype(float)\n",
    "        \n",
    "        # Rescale X\n",
    "        X = self.rescale*X\n",
    "        \n",
    "        # Calculate sum of squares of each row (sample) in X\n",
    "        X_sq_sum = (X**2).sum(axis = 1)\n",
    "        \n",
    "        # Calculate X' using amplitude or inverse of the standard stereographic projection\n",
    "        # encoding method\n",
    "        if self.encoding == 'amplit':\n",
    "            X_prime = normalize(np.concatenate((X, np.ones(m).reshape(-1, 1)), axis = 1))\n",
    "        elif self.encoding == 'stereo':\n",
    "            X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1) \\\n",
    "                      *(np.concatenate((2*X, (X_sq_sum - 1).reshape(-1, 1)), axis = 1))\n",
    "        else:\n",
    "            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n",
    "        return X_prime  \n",
    "    \n",
    "        \n",
    "    # Function for kronecker tensor product with broadcasting, set as global function\n",
    "    global kronecker\n",
    "    def kronecker(A, B):\n",
    "        return np.einsum('nab,ncd->nacbd', A, B).reshape(A.shape[0],\n",
    "                                                         A.shape[1]*B.shape[1],\n",
    "                                                         A.shape[2]*B.shape[2])\n",
    "    \n",
    "\n",
    "    # Set np.einsum subscripts (between unnested and nested objects) as a constant, set as global \n",
    "    # variable\n",
    "    global einsum_unnest, einsum_nest\n",
    "    einsum_unnest = 'ij,ji->'\n",
    "    einsum_nest = 'bij,ji->b'\n",
    "    \n",
    "    \n",
    "    # Function for fit\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Perform PGM-HQC classification with the amplitude and inverse of the standard \n",
    "        stereographic projection encoding methods, with the option to rescale the dataset prior \n",
    "        to encoding.\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples. An array of int or float.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The training input binary target values. An array of str, int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # Check data in X and y as required by scikit-learn v0.25\n",
    "        X, y = self._validate_data(X, y, reset = True)\n",
    "        \n",
    "        # Ensure target y is of non-regression type  \n",
    "        # Added as required by sklearn check_estimator\n",
    "        check_classification_targets(y)\n",
    "    \n",
    "        # Store classes and encode y into class indexes\n",
    "        self.classes_, y_class_index = np.unique(y, return_inverse = True)\n",
    "                \n",
    "        # Number of classes, set as global variable\n",
    "        global num_classes\n",
    "        num_classes = len(self.classes_)\n",
    "        \n",
    "        # Raise error when there are more than 2 classes and Helstrom measurement is specified\n",
    "        if num_classes > 2 and self.measure == 'hels':\n",
    "            raise ValueError('Helstrom measurement can be applied for binary classification only')\n",
    "        else:\n",
    "            # Number of rows and columns in X\n",
    "            m, n = X.shape[0], X.shape[1]\n",
    "            \n",
    "            # Calculate X_prime\n",
    "            X_prime = X_prime_func(self, X, m)\n",
    "        \n",
    "            # Number of columns in X', set as global variable\n",
    "            global n_prime\n",
    "            n_prime = n + 1\n",
    "        \n",
    "            # Function to calculate number of rows (samples) and Quantum Centroids for each class\n",
    "            def qcentroids_terms_func(i):\n",
    "                # Determine rows (samples) in X' belonging to each class\n",
    "                X_prime_class = X_prime[y_class_index == i]\n",
    "            \n",
    "                # Number of rows (samples) in X' belonging to either class\n",
    "                m_class = X_prime_class.shape[0]\n",
    "            \n",
    "                # Split X' belonging to each class into n_splits subsets, row-wise\n",
    "                X_prime_class_split = np.array_split(X_prime_class,\n",
    "                                                     indices_or_sections = self.n_splits,\n",
    "                                                     axis = 0)\n",
    "            \n",
    "                # Function to calculate the Quantum Centroids for each class, per subset split\n",
    "                def X_prime_class_split_func(j):\n",
    "                    # Counter for j-th split of X'\n",
    "                    X_prime_class_split_jth = X_prime_class_split[j]\n",
    "                \n",
    "                    # Number of rows (samples) in j-th split of X'\n",
    "                    m_class_split = X_prime_class_split_jth.shape[0]\n",
    "                \n",
    "                    # Encode vectors into quantum densities\n",
    "                    density_split = np.matmul(X_prime_class_split_jth.reshape(m_class_split, \n",
    "                                                                              n_prime, 1),\n",
    "                                              X_prime_class_split_jth.reshape(m_class_split, \n",
    "                                                                              1, n_prime))\n",
    "                                        \n",
    "                    # Calculate n-fold Kronecker tensor product\n",
    "                    if self.n_copies == 1:\n",
    "                        density_split = density_split\n",
    "                    else:\n",
    "                        density_split_copy = density_split\n",
    "                        for _ in range(self.n_copies - 1):\n",
    "                            density_split = kronecker(density_split, density_split_copy)\n",
    "                \n",
    "                    # Calculate sum of quantum densities\n",
    "                    density_split_sum = density_split.sum(axis = 0)\n",
    "                \n",
    "                    # Calculate Quantum Centroid for each class, per subset split\n",
    "                    # Added ZeroDivisionError as required by scikit-learn check_estimator()\n",
    "                    try:\n",
    "                        qcentroid = (1/m_class)*density_split_sum\n",
    "                    except ZeroDivisionError:\n",
    "                        qcentroid = 0\n",
    "                    return qcentroid\n",
    "                return m_class, np.sum(Parallel(n_jobs = self.n_jobs)(delayed(X_prime_class_split_func)(j) \n",
    "                                                                      for j in range(self.n_splits)), axis = 0)\n",
    "        \n",
    "            # Calculate number of rows (samples) and Quantum Centroids for each class\n",
    "            # Added dtype = object as required by NumPy v19.0 when creating ndarray from ragged nested sequences\n",
    "            qcentroids_terms = np.array(Parallel(n_jobs = self.n_jobs)(delayed(qcentroids_terms_func)(i) \n",
    "                                                                       for i in range(num_classes)), dtype = object)\n",
    "\n",
    "            # Determine Quantum Centroids\n",
    "            self.qcentroids_ = qcentroids_terms[:, 1]\n",
    "            \n",
    "            # Calculate class weight\n",
    "            if self.class_weight == None:\n",
    "                class_weight_terms = qcentroids_terms[:, 0]/m\n",
    "            elif self.class_weight == 'balanced':\n",
    "                class_weight_terms = np.array([1/num_classes for k in range(num_classes)])\n",
    "            else:\n",
    "                raise ValueError('class_weight should be None or \"balanced\"')\n",
    "                \n",
    "            # When Pretty Good Measurement is specified\n",
    "            if self.measure == 'pgm':                    \n",
    "                # Function to calculate R\n",
    "                def R_func(a):\n",
    "                    return class_weight_terms[a]*self.qcentroids_[a]\n",
    "                \n",
    "                # Calculate R\n",
    "                R = np.sum(Parallel(n_jobs = self.n_jobs)(delayed(R_func)(a) for a in range(num_classes)), axis = 0)\n",
    "                \n",
    "                # Calculate square root of the pseudo inverse of R, and remove complex part of the matrix\n",
    "                # created due to numerical precision/rounding issues in machine language\n",
    "                sqrt_pinv_R = np.real(linalg.sqrtm(np.linalg.pinv(R, hermitian = True)))\n",
    "                    \n",
    "                # Calculate kernel of R\n",
    "                ker_R = linalg.null_space(R)\n",
    "                    \n",
    "                # Calculate projector of kernel of R\n",
    "                proj_ker_R = np.dot(ker_R, ker_R.T)\n",
    "                    \n",
    "                # Function to calculate Pretty Good Measurement\n",
    "                def pgm_func(b):\n",
    "                    return np.linalg.multi_dot([sqrt_pinv_R, class_weight_terms[b]*self.qcentroids_[b], \\\n",
    "                                                sqrt_pinv_R]) + (1/num_classes)*proj_ker_R\n",
    "            \n",
    "                # Calculate Pretty Good Measurement\n",
    "                self.pgms_ = Parallel(n_jobs = self.n_jobs)(delayed(pgm_func)(b) for b in range(num_classes))\n",
    "                \n",
    "                # Function to calculate PGM bound\n",
    "                def pgm_bound_func(c):\n",
    "                    return class_weight_terms[c]*np.einsum(einsum_unnest, self.qcentroids_[c], self.pgms_[c])\n",
    "                \n",
    "                # Calculate PGM bound\n",
    "                self.pgm_bound_ = np.sum(Parallel(n_jobs = self.n_jobs)(delayed(pgm_bound_func)(c) \n",
    "                                                                        for c in range(num_classes)), axis = 0)\n",
    "            # When Helstrom measurement is specified\n",
    "            elif self.measure == 'hels':               \n",
    "                # Calculate quantum Helstrom observable\n",
    "                hels_obs = class_weight_terms[0]*self.qcentroids_[0] \\\n",
    "                           - class_weight_terms[1]*self.qcentroids_[1]\n",
    "            \n",
    "                # Number of rows/columns in density matrix, set as global variable\n",
    "                global density_nrow_ncol\n",
    "                density_nrow_ncol = hels_obs.shape[0]\n",
    "            \n",
    "                # Calculate eigenvalues w and unit eigenvectors v of the quantum Helstrom observable\n",
    "                w, v = np.linalg.eigh(hels_obs)\n",
    "                \n",
    "                # Length of w\n",
    "                len_w = len(w)\n",
    "                \n",
    "                # Initialize array eigval_class\n",
    "                eigval_class = np.empty_like(w)\n",
    "                for b in range(len_w):\n",
    "                    # Create an array of 0s and 1s to indicate positive and negative eigenvalues\n",
    "                    # respectively\n",
    "                    if w[b] > 0:\n",
    "                        eigval_class[b] = 0\n",
    "                    else:\n",
    "                        eigval_class[b] = 1\n",
    "                        \n",
    "                # Transpose matrix v containing unit eigenvectors to row-wise\n",
    "                eigvec = v.T\n",
    "                \n",
    "                # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "                # eigenvalues respectively\n",
    "                def sum_proj_func(c):\n",
    "                    # Determine unit eigenvectors belonging to positive and negative eigenvalues \n",
    "                    # respectively\n",
    "                    eigvec_class = eigvec[eigval_class == c]\n",
    "                    \n",
    "                    # Split unit eigenvectors into n_splits subsets\n",
    "                    eigvec_class_split = np.array_split(eigvec_class,\n",
    "                                                        indices_or_sections = self.n_splits,\n",
    "                                                        axis = 0)\n",
    "                    \n",
    "                    # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "                    # eigenvalues respectively, per subset split\n",
    "                    def eigvec_class_split_func(d):\n",
    "                        # Counter for d-th split of eigvec_class_split\n",
    "                        eigvec_class_split_dth = eigvec_class_split[d]\n",
    "                    \n",
    "                        # Number of rows (samples) in d-th split of eigvec_class_split\n",
    "                        m_eigvec_class_split = eigvec_class_split_dth.shape[0]\n",
    "                    \n",
    "                        # Calculate projectors corresponding to positive and negative eigenvalues\n",
    "                        # respectively, per subset split\n",
    "                        proj_split = np.matmul(eigvec_class_split_dth.reshape(m_eigvec_class_split,\n",
    "                                                                              density_nrow_ncol, 1),\n",
    "                                               eigvec_class_split_dth.reshape(m_eigvec_class_split,\n",
    "                                                                              1, density_nrow_ncol))\n",
    "\n",
    "                        # Calculate sum of projectors\n",
    "                        proj_split_sum = proj_split.sum(axis = 0)\n",
    "                        return proj_split_sum\n",
    "                    return np.sum(Parallel(n_jobs = self.n_jobs)(delayed(eigvec_class_split_func)(d) \n",
    "                                                                 for d in range(self.n_splits)), axis = 0)\n",
    "                \n",
    "                # Calculate sum of the projectors corresponding to positive and negative eigenvalues\n",
    "                # respectively\n",
    "                self.proj_sums_ = Parallel(n_jobs = self.n_jobs)(delayed(sum_proj_func)(c) for c in range(2))\n",
    "                \n",
    "                # Function to calculate Helstrom bound\n",
    "                def hels_bound_func(e):\n",
    "                    return class_weight_terms[e]*np.einsum(einsum_unnest, self.qcentroids_[e], self.proj_sums_[e])\n",
    "                \n",
    "                # Calculate Helstrom bound\n",
    "                self.hels_bound_ = np.sum(Parallel(n_jobs = self.n_jobs)(delayed(hels_bound_func)(e) \\\n",
    "                                                                         for e in range(2)))\n",
    "            # When Pretty Good Measurement or Helstrom measurement is misspecified\n",
    "            else:\n",
    "                raise ValueError('measure should be \"pgm\" or \"hels\"')\n",
    "        return self             \n",
    "\n",
    "    \n",
    "    # Function for predict_proba\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Performs PMG-HQC classification on X and returns the trace of the dot product of the \n",
    "        densities and the POV (positive operator-valued) measure, i.e. the class probabilities.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.       \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        trace_matrix : ndarray, shape (n_samples, n_classes)\n",
    "            Each column corresponds to the trace of the dot product of the densities and the POV \n",
    "            (positive operator-valued) measure for each class, i.e. each column corresponds to the \n",
    "            class probabilities. An array of float.\n",
    "        \"\"\"\n",
    "        # Check if fit had been called\n",
    "        if self.measure == 'pgm':\n",
    "            check_is_fitted(self, ['pgms_'])\n",
    "        else:\n",
    "            check_is_fitted(self, ['proj_sums_'])\n",
    "\n",
    "        # Check data in X as required by scikit-learn v0.25\n",
    "        X = self._validate_data(X, reset = False)\n",
    "        \n",
    "        # Number of rows in X\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Calculate X_prime\n",
    "        X_prime = X_prime_func(self, X, m)\n",
    "               \n",
    "        # Function to calculate trace values for each class\n",
    "        def trace_func(i):\n",
    "            # Split X' into n_splits subsets, row-wise\n",
    "            X_prime_split = np.array_split(X_prime, \n",
    "                                           indices_or_sections = self.n_splits, \n",
    "                                           axis = 0)\n",
    "            \n",
    "            # Function to calculate trace values for each class, per subset split\n",
    "            def trace_split_func(j):\n",
    "                # Counter for j-th split X'\n",
    "                X_prime_split_jth = X_prime_split[j]\n",
    "                \n",
    "                # Number of rows (samples) in j-th split X'\n",
    "                X_prime_split_m = X_prime_split_jth.shape[0]\n",
    "                \n",
    "                # Encode vectors into quantum densities\n",
    "                density_chunk = np.matmul(X_prime_split_jth.reshape(X_prime_split_m, n_prime, 1),\n",
    "                                          X_prime_split_jth.reshape(X_prime_split_m, 1, n_prime))\n",
    "                \n",
    "                # Calculate n-fold Kronecker tensor product\n",
    "                if self.n_copies == 1:\n",
    "                    density_chunk = density_chunk\n",
    "                else:\n",
    "                    density_chunk_copy = density_chunk\n",
    "                    for _ in range(self.n_copies - 1):\n",
    "                        density_chunk = kronecker(density_chunk, density_chunk_copy)\n",
    "                        \n",
    "                # When Pretty Good Measurement is specified\n",
    "                if self.measure == 'pgm':\n",
    "                    # Calculate trace of the dot product of density of each row and Pretty Good \n",
    "                    # Measurement\n",
    "                    trace_class_split = np.einsum(einsum_nest, density_chunk, self.pgms_[i])\n",
    "                # When Helstrom measurement is specified\n",
    "                else:               \n",
    "                    # Calculate trace of the dot product of density of each row and sum of \n",
    "                    # projectors with corresponding positive and negative eigenvalues respectively\n",
    "                    trace_class_split = np.einsum(einsum_nest, density_chunk, self.proj_sums_[i])\n",
    "                return trace_class_split\n",
    "            \n",
    "            # Calculate trace values for each class, per subset split\n",
    "            trace_class = Parallel(n_jobs = self.n_jobs)(delayed(trace_split_func)(j) \n",
    "                                                         for j in range(self.n_splits))\n",
    "            return np.concatenate(trace_class, axis = 0)\n",
    "        \n",
    "        # Calculate trace values for each class\n",
    "        trace_matrix = np.transpose(Parallel(n_jobs = self.n_jobs)(delayed(trace_func)(i) \n",
    "                                                                   for i in range(num_classes)))\n",
    "        return trace_matrix\n",
    "        \n",
    "    \n",
    "    # Function for predict\n",
    "    def predict(self, X):\n",
    "        \"\"\"Performs PGM-HQC classification on X and returns the classes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self.classes_[predict_trace_index] : ndarray, shape (n_samples,)\n",
    "            The predicted classes. An array of str, int or float.\n",
    "        \"\"\"\n",
    "        # Determine column index with the higher trace value in trace_matrix\n",
    "        # If columns have the same trace value, returns column with the smallest column index value\n",
    "        predict_trace_index = np.argmax(self.predict_proba(X), axis = 1)\n",
    "        # Returns the predicted classes\n",
    "        return self.classes_[predict_trace_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "class_weight should be None or \"balanced\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2fa41a05a4af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_checks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcheck_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPGMHQC_fast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\estimator_checks.py\u001b[0m in \u001b[0;36mcheck_estimator\u001b[1;34m(Estimator, generate_only)\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchecks_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSkipTest\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m             \u001b[1;31m# the only SkipTest thrown currently results from not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_testing.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\estimator_checks.py\u001b[0m in \u001b[0;36mcheck_class_weight_classifiers\u001b[1;34m(name, classifier_orig)\u001b[0m\n\u001b[0;32m   2343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2344\u001b[0m         \u001b[0mset_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2345\u001b[1;33m         \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2346\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2347\u001b[0m         \u001b[1;31m# XXX: Generally can use 0.89 here. On Windows, LinearSVC gets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-231867876a3c>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    235\u001b[0m                 \u001b[0mclass_weight_terms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'class_weight should be None or \"balanced\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;31m# When Pretty Good Measurement is specified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: class_weight should be None or \"balanced\""
     ]
    }
   ],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "check_estimator(PGMHQC_fast())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
