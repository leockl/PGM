{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update scikit-learn to lastest version\n",
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "from scipy import linalg\n",
    "\n",
    "class PGMHQC_gpu_dtype(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"The Pretty Good Measurement (PGM) - Helstrom Quantum Centroid (HQC) classifier is a \n",
    "    quantum-inspired supervised classification approach for data with multiple classes.\n",
    "                         \n",
    "    Parameters\n",
    "    ----------\n",
    "    rescale : int or float, default = 1\n",
    "        The dataset rescaling factor. A parameter used for rescaling the dataset. \n",
    "    encoding : str, default = 'amplit'\n",
    "        The encoding method used to encode vectors into quantum densities. Possible values:\n",
    "        'amplit', 'stereo'. 'amplit' means using the amplitude encoding method. 'stereo' means \n",
    "        using the inverse of the standard stereographic projection encoding method. Default set \n",
    "        to 'amplit'.\n",
    "    n_copies : int, default = 1\n",
    "        The number of copies to take for each quantum density. This is equivalent to taking \n",
    "        the n-fold Kronecker tensor product for each quantum density.\n",
    "    measure : str, default = 'pgm'\n",
    "        The measurement used to distinguish between quantum states. Possible values: 'pgm', \n",
    "        'hels'. The value 'pgm' stands for \"Pretty Good Measurement\", 'hels' stands for \n",
    "        \"Helstrom measurement\" (applicable only for binary classification). Default set to \n",
    "        'pgm'. \n",
    "    class_weight : str, default = None        \n",
    "        Weights associated with classes. This is the class weights assigned to the quantum \n",
    "        centroids in the Pretty Good Measurement or Helstrom observable. Possible values: None,\n",
    "        'balanced'. If None given, all classes are supposed to have weight one. The 'balanced' \n",
    "        mode uses the values of y to automatically adjust weights inversely proportional to class\n",
    "        frequencies in the input data as n_samples / (n_classes * np.bincount(y)). Default set\n",
    "        to None.       \n",
    "    n_splits : int, default = 1\n",
    "        The number of subset splits performed on the input dataset row-wise and on the number \n",
    "        of eigenvalues/eigenvectors of the Quantum Helstrom observable for optimal speed \n",
    "        performance. If 1 is given, no splits are performed. For optimal speed, recommend \n",
    "        using small values as close to 1 as possible. If memory blow-out occurs, increase \n",
    "        n_splits.\n",
    "    dtype : torch.float32 or torch.float64, default = torch.float64\n",
    "        The float datatype used for the elements in the Pytorch tensor dataset. Datatype has to\n",
    "        be of float to ensure calculations are done in float rather than integer. To achieve\n",
    "        higher n_copies without memory blow-out issues, reduce float precision, which may or may   \n",
    "        not affect accuracy in a significant way.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : ndarray, shape (n_classes,)\n",
    "        Sorted classes.\n",
    "    qcentroids_ : ndarray, shape (n_classes, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Quantum Centroids for each class.\n",
    "    pgms_ : list, shape (n_classes, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Values for the Pretty Good Measurements. Only applicable when Pretty Good Measurement is \n",
    "        selected.\n",
    "    pgm_bound_ : float\n",
    "        Pretty Good Measurement bound is the upper bound on the probability that one can correctly\n",
    "        discriminate whether a quantum density is of which of the (multiclass) N quantum density \n",
    "        patterns. Only applicable when Pretty Good Measurement is selected.\n",
    "    proj_sums_ : list, shape (n_classes, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Sum of the projectors of the Quantum Helstrom observable's unit eigenvectors, which has\n",
    "        corresponding positive and negative eigenvalues respectively. Only applicable when Helstrom\n",
    "        Measurement is selected.\n",
    "    hels_bound_ : float\n",
    "        Helstrom bound is the upper bound on the probability that one can correctly \n",
    "        discriminate whether a quantum density is of which of the two binary quantum density \n",
    "        pattern. Only applicable when Helstrom Measurement is selected.         \n",
    "    \"\"\"   \n",
    "    # Initialize model hyperparameters\n",
    "    def __init__(self, \n",
    "                 rescale = 1,\n",
    "                 encoding = 'amplit',\n",
    "                 n_copies = 1,  \n",
    "                 measure = 'pgm',\n",
    "                 class_weight = None, \n",
    "                 n_splits = 1,\n",
    "                 dtype = torch.float64):\n",
    "        self.rescale = rescale\n",
    "        self.encoding = encoding\n",
    "        self.n_copies = n_copies\n",
    "        self.measure = measure\n",
    "        self.class_weight = class_weight\n",
    "        self.n_splits = n_splits\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        # Raise error if dtype is not torch.float32 or torch.float64\n",
    "        if self.dtype not in [torch.float32, torch.float64]:\n",
    "            raise ValueError('dtype should be torch.float32 or torch.float64 only')\n",
    "        \n",
    "\n",
    "    # Function for X_prime, set as global function\n",
    "    global X_prime_func\n",
    "    def X_prime_func(self, X, m):\n",
    "        # Cast array X into a floating point tensor to ensure all following calculations below  \n",
    "        # are done in float rather than integer, and send tensor X from CPU to GPU\n",
    "        X = torch.tensor(X, dtype = self.dtype).cuda()\n",
    "        \n",
    "        # Rescale X\n",
    "        X = self.rescale*X\n",
    "        \n",
    "        # Calculate sum of squares of each row (sample) in X\n",
    "        X_sq_sum = (X**2).sum(dim = 1)\n",
    "        \n",
    "        # Calculate X' using amplitude or inverse of the standard stereographic projection \n",
    "        # encoding method\n",
    "        if self.encoding == 'amplit':\n",
    "            X_prime = normalize(torch.cat([X, torch.ones(m, dtype = self.dtype) \\\n",
    "                                           .reshape(-1, 1).cuda()], dim = 1), p = 2, dim = 1)\n",
    "        elif self.encoding == 'stereo':\n",
    "            X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1)*(torch.cat((2*X, (X_sq_sum - 1) \\\n",
    "                                                                      .reshape(-1, 1)), dim = 1))\n",
    "        else:\n",
    "            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n",
    "        return X_prime\n",
    "        \n",
    "        \n",
    "    # Function for kronecker tensor product for PyTorch tensors, set as global function\n",
    "    global kronecker\n",
    "    def kronecker(A, B):\n",
    "        return torch.einsum('nab,ncd->nacbd', A, B).view(A.size(0), \n",
    "                                                         A.size(1)*B.size(1), \n",
    "                                                         A.size(2)*B.size(2))\n",
    "    \n",
    "\n",
    "    # Set np.einsum subscripts (between unnested and nested objects) as a constant, set as global\n",
    "    # variable\n",
    "    global einsum_unnest, einsum_nest\n",
    "    einsum_unnest = 'ij,ji->'\n",
    "    einsum_nest = 'bij,ji->b'\n",
    "    \n",
    "    \n",
    "    # Function for fit\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Perform PGM-HQC classification with the amplitude and inverse of the standard \n",
    "        stereographic projection encoding methods, with the option to rescale the dataset prior \n",
    "        to encoding.\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples. An array of int or float.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The training input binary target values. An array of str, int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # Check data in X and y as required by scikit-learn v0.25\n",
    "        X, y = self._validate_data(X, y, reset = True)\n",
    "        \n",
    "        # Ensure target array y is of non-regression type  \n",
    "        # Added as required by sklearn check_estimator\n",
    "        check_classification_targets(y)\n",
    "            \n",
    "        # Store classes and encode y into class indexes\n",
    "        self.classes_, y_class_index = np.unique(y, return_inverse = True)\n",
    "        \n",
    "        # Number of classes, set as global variable\n",
    "        global num_classes\n",
    "        num_classes = len(self.classes_)\n",
    "        \n",
    "        # Raise error when there are more than 2 classes and Helstrom measurement is specified\n",
    "        if num_classes > 2 and self.measure == 'hels':\n",
    "            raise ValueError('Helstrom measurement can be applied for binary classification only')\n",
    "        else:\n",
    "            # Number of rows and columns in X\n",
    "            m, n = X.shape[0], X.shape[1]\n",
    "            \n",
    "            # Calculate X_prime\n",
    "            X_prime = X_prime_func(self, X, m)\n",
    "                   \n",
    "            # Number of columns in X', set as global variable\n",
    "            global n_prime\n",
    "            n_prime = n + 1\n",
    "        \n",
    "            # Function to calculate number of rows (samples) and Quantum Centroids for each class \n",
    "            def qcentroids_terms_func(i):\n",
    "                # Cast array y_class_index into a tensor and send from CPU to GPU\n",
    "                # Determine rows (samples) in X' belonging to either class\n",
    "                X_prime_class = X_prime[torch.CharTensor(y_class_index).cuda() == i]\n",
    "                                    \n",
    "                # Split X' belonging to either class into n_splits subsets, row-wise\n",
    "                # Send tensors from GPU to CPU and cast tensors into arrays, use np.array_split()\n",
    "                # because the equivalent torch.chunk() doesn't behave similarly to np.array_split()\n",
    "                X_prime_class_split_arr = np.array_split(X_prime_class.cpu().numpy(),\n",
    "                                                         indices_or_sections = self.n_splits,\n",
    "                                                         axis = 0)\n",
    "            \n",
    "                # Cast arrays back to tensors and send back from CPU to GPU\n",
    "                X_prime_class_split = [torch.tensor(a, dtype = self.dtype).cuda() \n",
    "                                       for a in X_prime_class_split_arr]\n",
    "            \n",
    "                # Function to calculate sum of quantum densities belonging to each class, \n",
    "                # per subset split\n",
    "                def X_prime_class_split_func(j):\n",
    "                    # Counter for j-th split of X'\n",
    "                    X_prime_class_split_jth = X_prime_class_split[j]\n",
    "                \n",
    "                    # Number of rows (samples) in j-th split of X'\n",
    "                    m_class_split = X_prime_class_split_jth.shape[0]\n",
    "                \n",
    "                    # Encode vectors into quantum densities\n",
    "                    density_chunk = torch.matmul(X_prime_class_split_jth.view(m_class_split, \n",
    "                                                                              n_prime, 1),\n",
    "                                                 X_prime_class_split_jth.view(m_class_split, \n",
    "                                                                              1, n_prime))\n",
    "                \n",
    "                    # Calculate n-fold Kronecker tensor product\n",
    "                    if self.n_copies == 1:\n",
    "                        density_chunk = density_chunk\n",
    "                    else:\n",
    "                        density_chunk_copy = density_chunk\n",
    "                        for _ in range(self.n_copies - 1):\n",
    "                            density_chunk = kronecker(density_chunk, density_chunk_copy)\n",
    "                    \n",
    "                    # Calculate sum of quantum densities\n",
    "                    density_chunk_sum = density_chunk.sum(dim = 0)\n",
    "                    return density_chunk_sum\n",
    "\n",
    "                # Number of rows/columns in density matrix, set as global variable\n",
    "                global density_nrow_ncol\n",
    "                density_nrow_ncol = n_prime**self.n_copies\n",
    "            \n",
    "                # Initialize tensor density_class_sum\n",
    "                density_class_sum = torch.zeros([density_nrow_ncol, density_nrow_ncol], \n",
    "                                                dtype = self.dtype).cuda()\n",
    "                for j in range(self.n_splits):\n",
    "                    # Calculate sum of quantum densities belonging to each class\n",
    "                    density_class_sum = density_class_sum + X_prime_class_split_func(j)\n",
    "            \n",
    "                # Number of rows (samples) in X' belonging to each class\n",
    "                m_class = X_prime_class.shape[0]\n",
    "            \n",
    "                # Function to calculate Quantum Centroid belonging to each class\n",
    "                def qcentroid_func():\n",
    "                    # Calculate Quantum Centroid belonging to each class\n",
    "                    # Added ZeroDivisionError as required by sklearn check_estimator\n",
    "                    try:\n",
    "                        qcentroid = (1/m_class)*density_class_sum\n",
    "                    except ZeroDivisionError:\n",
    "                        qcentroid = 0 \n",
    "                    return qcentroid\n",
    "            \n",
    "                # Calculate Quantum Centroid belonging to each class\n",
    "                qcentroid_class = qcentroid_func()\n",
    "                return m_class, qcentroid_class\n",
    "            \n",
    "            # Calculate number of rows (samples) and Quantum Centroids for each class \n",
    "            qcentroids_terms = [qcentroids_terms_func(i) for i in range(num_classes)]\n",
    "\n",
    "            # Determine Quantum Centroids\n",
    "            self.qcentroids_ = torch.stack([qcentroids_terms[z][1] for z in range(num_classes)], dim = 0)\n",
    "\n",
    "            # Calculate class weight\n",
    "            if self.class_weight == None:\n",
    "                class_weight_terms = torch.tensor([qcentroids_terms[y][0] for y in range(num_classes)], \\\n",
    "                                                  dtype = self.dtype)/m\n",
    "            elif self.class_weight == 'balanced':\n",
    "                class_weight_terms = torch.tensor([1/num_classes for k in range(num_classes)], \\\n",
    "                                                  dtype = self.dtype)\n",
    "            else:\n",
    "                raise ValueError('class_weight should be None or \"balanced\"')\n",
    "            \n",
    "            # When Pretty Good Measurement is specified\n",
    "            if self.measure == 'pgm':\n",
    "                # Function to calculate R\n",
    "                def R_func(a):\n",
    "                    return class_weight_terms[a]*self.qcentroids_[a]\n",
    "\n",
    "                # Calculate R\n",
    "                R = torch.stack([R_func(a) for a in range(num_classes)], dim = 0).sum(dim = 0)\n",
    "              \n",
    "                # Calculate square root of pseudo inverse of R\n",
    "                # Change datatype of R to float64 as the square root of a matrix calculation is highly \n",
    "                # senstive to numerical precision/rounding\n",
    "                # Calculate pseudo inverse of R, send tensor from GPU to CPU and cast into an array\n",
    "                # Use scipy.linalg.sqrtm() to calculate square root of the pseudo inverse of R because \n",
    "                # there is no equivalent function in PyTorch which behaves numerically similarly \n",
    "                # Remove complex part of the matrix created due to numerical precision/rounding issues\n",
    "                # in machine language\n",
    "                # Cast array back into a tensor and send back from CPU to GPU\n",
    "                sqrt_pinv_R = torch.tensor(np.real(linalg.sqrtm(torch.pinverse(torch.as_tensor(R, dtype = \\\n",
    "                                           torch.float64)).cpu().numpy())), dtype = self.dtype).cuda()\n",
    "                    \n",
    "                # Calculate kernel of R\n",
    "                # Change datatype of R to float64 as the kernel of a matrix calculation is highly\n",
    "                # senstive to numerical precision/rounding\n",
    "                # Send tensor from GPU to CPU and cast into an array, use scipy.linalg.null_space()\n",
    "                # to calculate kernel because there is no equivalent function in PyTorch which\n",
    "                # behaves numerically similarly\n",
    "                # Cast array back into a tensor and send back from CPU to GPU\n",
    "                ker_R = torch.tensor(linalg.null_space(torch.as_tensor(R, dtype = torch.float64).cpu() \\\n",
    "                                     .numpy()), dtype = self.dtype).cuda()\n",
    "                    \n",
    "                # Calculate projector of kernel of R\n",
    "                proj_ker_R = torch.matmul(ker_R, ker_R.T)\n",
    "                    \n",
    "                # Function to calculate Pretty Good Measurement\n",
    "                def pgm_func(b):\n",
    "                    return torch.matmul(torch.matmul(sqrt_pinv_R, class_weight_terms[b]*self.qcentroids_[b]), \n",
    "                                        sqrt_pinv_R) + (1/num_classes)*proj_ker_R\n",
    "                                               \n",
    "                # Calculate Pretty Good Measurement\n",
    "                self.pgms_ = torch.stack([pgm_func(b) for b in range(num_classes)], dim = 0)\n",
    "\n",
    "                # Function to calculate PGM bound\n",
    "                def pgm_bound_func(c):\n",
    "                    return class_weight_terms[c]*torch.einsum(einsum_unnest, self.qcentroids_[c], self.pgms_[c])\n",
    "\n",
    "                # Calculate PGM bound\n",
    "                self.pgm_bound_ = torch.stack([pgm_bound_func(c) for c in range(num_classes)], dim = 0) \\\n",
    "                                             .sum(dim = 0).item()\n",
    "            # When Helstrom measurement is specified\n",
    "            elif self.measure == 'hels':\n",
    "                # Calculate quantum Helstrom observable\n",
    "                hels_obs = class_weight_terms[0]*self.qcentroids_[0] \\\n",
    "                           - class_weight_terms[1]*self.qcentroids_[1]\n",
    "                \n",
    "                # Number of rows/columns in density matrix, set as global variable\n",
    "                global density_nrow_ncol\n",
    "                density_nrow_ncol = hels_obs.shape[0]\n",
    "                \n",
    "                # Calculate eigenvalues w and unit eigenvectors v of the quantum Helstrom observable\n",
    "                w, v = torch.symeig(hels_obs, eigenvectors = True)\n",
    "                \n",
    "                # Length of w\n",
    "                len_w = len(w)\n",
    "                \n",
    "                # Initialize tensor eigval_class\n",
    "                eigval_class = torch.empty_like(w, dtype = self.dtype).cuda()\n",
    "                for d in range(len_w):\n",
    "                    # Create a tensor of 0s and 1s to indicate positive and negative eigenvalues\n",
    "                    # respectively\n",
    "                    if w[d] > 0:\n",
    "                        eigval_class[d] = 0\n",
    "                    else:\n",
    "                        eigval_class[d] = 1\n",
    "                        \n",
    "                # Transpose matrix v containing eigenvectors to row-wise\n",
    "                eigvec = v.T\n",
    "                \n",
    "                # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "                # eigenvalues respectively\n",
    "                def sum_proj_func(e):\n",
    "                    # Split eigenvectors belonging to positive or negative eigenvalues into n_splits subsets\n",
    "                    # Send tensors from GPU to CPU and cast tensors into arrays, use np.array_split()\n",
    "                    # because the equivalent torch.chunk() doesn't behave similarly to np.array_split()\n",
    "                    eigvec_class_split_arr_full = np.array_split(eigvec.cpu().numpy()[eigval_class.cpu() == e],\n",
    "                                                                 indices_or_sections = self.n_splits,\n",
    "                                                                 axis = 0)\n",
    "                    \n",
    "                    # Remove empty rows in eigvec_class_split_arr_full\n",
    "                    eigvec_class_split_arr = [f for f in eigvec_class_split_arr_full if f.shape[0] > 0]\n",
    "                    \n",
    "                    # Cast arrays back to tensors and send back from CPU to GPU\n",
    "                    eigvec_class_split = [torch.tensor(g, dtype = self.dtype).cuda()\n",
    "                                          for g in eigvec_class_split_arr]\n",
    "                    \n",
    "                    # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "                    # eigenvalues respectively, per subset split\n",
    "                    def eigvec_class_split_func(h):\n",
    "                        # Counter for h-th split of eigvec\n",
    "                        eigvec_class_split_hth = eigvec_class_split[h]\n",
    "                        \n",
    "                        # Number of rows (samples) in h-th split of eigvec\n",
    "                        m_eigvec_class_split = eigvec_class_split_hth.shape[0]\n",
    "                        \n",
    "                        # Calculate projectors corresponding to positive and negative eigenvalues\n",
    "                        # respectively, per subset split\n",
    "                        proj_split = torch.matmul(eigvec_class_split_hth.view(m_eigvec_class_split,\n",
    "                                                                              density_nrow_ncol, 1),\n",
    "                                                  eigvec_class_split_hth.view(m_eigvec_class_split,\n",
    "                                                                              1, density_nrow_ncol))\n",
    "                        \n",
    "                        # Calculate sum of projectors\n",
    "                        proj_split_sum = proj_split.sum(dim = 0)\n",
    "                        return proj_split_sum\n",
    "                    \n",
    "                    # Determine length of eigvec_class_split_arr\n",
    "                    eigvec_class_split_arr_len = len(eigvec_class_split_arr)\n",
    "                    \n",
    "                    # Initialize tensor proj_class_sum\n",
    "                    proj_class_sum = torch.zeros([density_nrow_ncol, density_nrow_ncol],\n",
    "                                                 dtype = self.dtype).cuda()\n",
    "                    for h in range(eigvec_class_split_arr_len):\n",
    "                        # Calculate sum of the projectors corresponding to positive and negative eigenvalues\n",
    "                        # respectively\n",
    "                        proj_class_sum = proj_class_sum + eigvec_class_split_func(h)\n",
    "                    return proj_class_sum\n",
    "                \n",
    "                # Calculate sum of the projectors corresponding to positive and negative eigenvalues\n",
    "                # respectively\n",
    "                self.proj_sums_ = torch.stack([sum_proj_func(0), sum_proj_func(1)], dim = 0)\n",
    "                \n",
    "                # Calculate Helstrom bound\n",
    "                self.hels_bound_ = (class_weight_terms[0]*torch.einsum(einsum_unnest, self.qcentroids_[0],\n",
    "                                                                      self.proj_sums_[0])).item() \\\n",
    "                                   + (class_weight_terms[1]*torch.einsum(einsum_unnest, self.qcentroids_[1],\n",
    "                                                                        self.proj_sums_[1])).item()\n",
    "            # When Pretty Good Measurement or Helstrom measurement is misspecified\n",
    "            else:\n",
    "                raise ValueError('measure should be \"pgm\" or \"hels\"')\n",
    "        return self\n",
    "\n",
    "           \n",
    "    # Function for predict_proba\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Performs PMG-HQC classification on X and returns the trace of the dot product of the \n",
    "        densities and the POV (positive operator-valued) measure, i.e. the class probabilities.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.       \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        trace_matrix : array-like, shape (n_samples, n_classes)\n",
    "            Each column corresponds to the trace of the dot product of the densities and the POV \n",
    "            (positive operator-valued) measure for each class, i.e. each column corresponds to the \n",
    "            class probabilities. An array of float.\n",
    "        \"\"\"\n",
    "        # Send tensors self.pgms_ and self.proj_sums_ from GPU to CPU and cast into an array, and\n",
    "        # check if fit had been called\n",
    "        if self.measure == 'pgm':\n",
    "            self.pgms_arr_ = self.pgms_.cpu().numpy()\n",
    "            check_is_fitted(self, ['pgms_arr_'])\n",
    "        else:\n",
    "            self.proj_sums_arr_ = self.proj_sums_.cpu().numpy()\n",
    "            check_is_fitted(self, ['proj_sums_arr_'])\n",
    "               \n",
    "        # Check data in X as required by scikit-learn v0.25\n",
    "        X = self._validate_data(X, reset = False)\n",
    "        \n",
    "        # Number of rows in X\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Calculate X_prime\n",
    "        X_prime = X_prime_func(self, X, m)\n",
    "                       \n",
    "        # Function to calculate trace values for each class\n",
    "        def trace_func(i):\n",
    "            # Split X' into n_splits subsets, row-wise\n",
    "            # Send tensors from GPU to CPU and cast tensors into arrays, use np.array_split()\n",
    "            # because the equivalent torch.chunk() doesn't behave similarly to np.array_split()\n",
    "            X_prime_split_arr_full = np.array_split(X_prime.cpu().numpy(),\n",
    "                                                    indices_or_sections = self.n_splits,\n",
    "                                                    axis = 0)\n",
    "            \n",
    "            # Remove empty rows in X_prime_split_arr_full\n",
    "            X_prime_split_arr = [a for a in X_prime_split_arr_full if a.shape[0] > 0]\n",
    "\n",
    "            # Cast arrays back to tensors and send back from CPU to GPU\n",
    "            X_prime_split = [torch.tensor(q, dtype = self.dtype).cuda() for q in X_prime_split_arr]\n",
    "            \n",
    "            # Function to calculate trace values for each class, per subset split\n",
    "            def trace_split_func(j):\n",
    "                # Counter for j-th split X'\n",
    "                X_prime_split_jth = X_prime_split[j]\n",
    "                \n",
    "                # Number of rows (samples) in j-th split X'\n",
    "                X_prime_split_m = X_prime_split_jth.shape[0]\n",
    "                \n",
    "                # Encode vectors into quantum densities\n",
    "                density_chunk = torch.matmul(X_prime_split_jth.view(X_prime_split_m, n_prime, 1),\n",
    "                                             X_prime_split_jth.view(X_prime_split_m, 1, n_prime))\n",
    "                \n",
    "                # Calculate n-fold Kronecker tensor product\n",
    "                if self.n_copies == 1:\n",
    "                    density_chunk = density_chunk\n",
    "                else:\n",
    "                    density_chunk_copy = density_chunk\n",
    "                    for _ in range(self.n_copies - 1):\n",
    "                        density_chunk = kronecker(density_chunk, density_chunk_copy)\n",
    "                        \n",
    "                # When Pretty Good Measurement is specified\n",
    "                if self.measure == 'pgm':\n",
    "                    # Calculate trace of the dot product of density of each row and Pretty Good\n",
    "                    # Measurement\n",
    "                    trace_class_split = torch.einsum(einsum_nest, density_chunk, self.pgms_[i])\n",
    "                # When Helstrom measurement is specified\n",
    "                else:\n",
    "                    # Calculate trace of the dot product of density of each row and sum of \n",
    "                    # projectors with corresponding positive and negative eigenvalues respectively\n",
    "                    trace_class_split = torch.einsum(einsum_nest, density_chunk, self.proj_sums_[i])\n",
    "                return trace_class_split\n",
    "            \n",
    "            # Determine length of X_prime_split_arr\n",
    "            X_prime_split_arr_len = len(X_prime_split_arr)\n",
    "\n",
    "            # Initialize tensor trace_class\n",
    "            trace_class = torch.empty([0], dtype = self.dtype).cuda()\n",
    "            for j in range(X_prime_split_arr_len):\n",
    "                # Calculate trace values for each class, per subset split\n",
    "                trace_class = torch.cat([trace_class, trace_split_func(j)], dim = 0)\n",
    "            return trace_class\n",
    "        \n",
    "        # Calculate trace values for each class, send from GPU to CPU and cast into an array\n",
    "        trace_matrix = torch.stack([trace_func(i) for i in range(num_classes)], dim = 1).cpu().numpy()\n",
    "        return trace_matrix\n",
    "                \n",
    "    \n",
    "    # Function for predict\n",
    "    def predict(self, X):\n",
    "        \"\"\"Performs PGM-HQC classification on X and returns the classes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self.classes_[predict_trace_index] : array-like, shape (n_samples,)\n",
    "            The predicted binary classes. An array of str, int or float.\n",
    "        \"\"\"\n",
    "        # Determine column index with the higher trace value in trace_matrix\n",
    "        # Cast predict_proba(X) from an array into a tensor and send from CPU to GPU\n",
    "        # If both columns have the same trace value, returns column index 1, which is different \n",
    "        # to np.argmax() which returns column index 0\n",
    "        predict_trace_index = torch.argmax(torch.tensor(self.predict_proba(X), \n",
    "                                                        dtype = self.dtype).cuda(), axis = 1)\n",
    "        # Returns the predicted binary classes, send tensor from GPU to CPU and cast tensor\n",
    "        # into an array\n",
    "        return self.classes_[predict_trace_index.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surpress warnings (not errors) when some classes have no predicted samples \n",
    "# (for eg. OneVsRestClassifier with precision_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hqc_ovr_ovo_gpu(file_path, file_name, n_copies_val, n_jobs_val, n_splits_val):\n",
    "# def hqc_ovr_ovo_gpu(file_path, file_name, n_copies_val, n_splits_val, dtype_val):\n",
    "def hqc_ovr_ovo_gpu_gcp(file_name, strat, n_copies_val, n_splits_val, dtype_val):\n",
    "    # df = pd.read_csv(file_path + r'\\Datasets' + r'\\\\' + file_name, delimiter='\\t')\n",
    "    # df = pd.read_csv(file_path + '/' + 'kagg-' + file_name + '/' + file_name + '.tsv', delimiter='\\t')\n",
    "    df = pd.read_csv(file_name + '.tsv', delimiter='\\t')\n",
    "    X = df.drop('target', axis=1).values\n",
    "    y = df['target'].values\n",
    "\n",
    "    # classes = np.unique(y)\n",
    "    # num_classes = len(classes)\n",
    "\n",
    "    # Use 80/20% train/test split and stratified sampling\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "    scores_all = ['precision_weighted',\n",
    "                  'recall_weighted',\n",
    "                  'balanced_accuracy',\n",
    "                  'f1_weighted',\n",
    "                  'roc_auc_ovr_weighted',\n",
    "                  'roc_auc_ovo_weighted']\n",
    "\n",
    "    # Create rescale hyperparamter list [0.1, 0.5, 1, 1.5,...,10.0]\n",
    "    rescale_list = [0.1]\n",
    "    rescale_list_add = np.linspace(0.5, 10, 20).tolist()\n",
    "    rescale_list.extend(rescale_list_add)\n",
    "\n",
    "    param_grid = {'estimator__rescale':rescale_list,\n",
    "                  'estimator__encoding':['amplit', 'stereo'],\n",
    "                  'estimator__class_weight':[None, 'balanced']}\n",
    "\n",
    "    # n_copies_val = [1,2,3,4]\n",
    "\n",
    "    # n_jobs_val = 16\n",
    "    # n_splits_val = int(np.ceil(n_jobs_val/num_classes))\n",
    "\n",
    "    if strat == 'ovr, ovo':\n",
    "        # Initialize array containing strings with 13 characters or less\n",
    "        best_score_std_dev_n_copies_ovr = np.empty((len(n_copies_val), len(scores_all)), dtype='<U13')\n",
    "\n",
    "        for j, nc in enumerate(n_copies_val):\n",
    "            # Initialize array containing strings with 13 characters or less\n",
    "            best_score_std_dev = np.empty(len(scores_all), dtype='<U13')\n",
    "\n",
    "            for i, sc in enumerate(scores_all):\n",
    "                # Fitting model, using GridSearchCV with default 5 folds and default stratified sampling\n",
    "                # models = GridSearchCV(OneVsRestClassifier(PGMHQC_gpu_dtype(n_copies=nc, measure='hels', n_jobs=n_jobs_val, \\\n",
    "                                                                           # n_splits=n_splits_val)), param_grid, scoring=sc) \\\n",
    "                models = GridSearchCV(OneVsRestClassifier(PGMHQC_gpu_dtype(n_copies=nc, measure='hels', \\\n",
    "                                                                           n_splits=n_splits_val, dtype=dtype_val)), \\\n",
    "                                                                           param_grid, scoring=sc) \\\n",
    "                                                                           .fit(X_train, y_train)\n",
    "        \n",
    "                results_table = pd.DataFrame(models.cv_results_)\n",
    "                # results_table.to_excel(file_path + r'\\OvO and OvR\\Output datasets\\gridsearchcv'\n",
    "                                       # + r'\\\\' + file_name\n",
    "                results_table.to_excel(file_name + '.tsv'\n",
    "                                       + '-hqc' + f'{nc}'\n",
    "                                       + '-ovr'\n",
    "                                       + '-' + sc\n",
    "                                       + '-gridsearchcv.xlsx')                      \n",
    "                              \n",
    "                # Get best score on test set\n",
    "                best_model = models.best_estimator_\n",
    "\n",
    "                if sc=='precision_weighted':\n",
    "                    y_hat = best_model.predict(X_test)\n",
    "                    best_score = metrics.precision_score(y_test, y_hat, average='weighted')\n",
    "                if sc=='recall_weighted':\n",
    "                    y_hat = best_model.predict(X_test)\n",
    "                    best_score = metrics.recall_score(y_test, y_hat, average='weighted')\n",
    "                if sc=='balanced_accuracy':\n",
    "                    y_hat = best_model.predict(X_test)\n",
    "                    best_score = metrics.balanced_accuracy_score(y_test, y_hat)\n",
    "                if sc=='f1_weighted':\n",
    "                    y_hat = best_model.predict(X_test)\n",
    "                    best_score = metrics.f1_score(y_test, y_hat, average='weighted')\n",
    "                if sc=='roc_auc_ovr_weighted':\n",
    "                    y_score = best_model.predict_proba(X_test)\n",
    "                    best_score = metrics.roc_auc_score(y_test, y_score, average='weighted', multi_class='ovr')\n",
    "                if sc=='roc_auc_ovo_weighted':\n",
    "                    y_score = best_model.predict_proba(X_test)\n",
    "                    best_score = metrics.roc_auc_score(y_test, y_score, average='weighted', multi_class='ovo')\n",
    "    \n",
    "                # Get best std. dev. on validation set\n",
    "                best_std_dev = models.cv_results_['std_test_score'][models.best_index_]\n",
    "                          \n",
    "                best_score_std_dev[i] = format(best_score, '.3f') + ' ± ' + format(best_std_dev, '.3f')\n",
    "    \n",
    "            best_score_std_dev_n_copies_ovr[j,:] = best_score_std_dev.reshape(1,-1)\n",
    "\n",
    "    \n",
    "        # Initialize array containing strings with 13 characters or less\n",
    "        best_score_std_dev_n_copies_ovo = np.empty((len(n_copies_val), len(scores_all)), dtype='<U13')\n",
    "                              \n",
    "        for k, nc in enumerate(n_copies_val):\n",
    "            # Initialize array containing strings with 13 characters or less\n",
    "            best_score_std_dev = np.empty(len(scores_all), dtype='<U13')\n",
    "                              \n",
    "            for i, sc in enumerate(scores_all):\n",
    "                # OneVsOneClassifier does not have roc_auc\n",
    "                if sc not in ['roc_auc_ovr_weighted', 'roc_auc_ovo_weighted']:\n",
    "                    # Fitting model, using GridSearchCV with default 5 folds and default stratified sampling\n",
    "                    # models = GridSearchCV(OneVsOneClassifier(PGMHQC_gpu_dtype(n_copies=nc, measure='hels', n_jobs=n_jobs_val, \\\n",
    "                                                                              # n_splits=n_splits_val)), param_grid, scoring=sc) \\\n",
    "                    models = GridSearchCV(OneVsOneClassifier(PGMHQC_gpu_dtype(n_copies=nc, measure='hels', \\\n",
    "                                                                              n_splits=n_splits_val, dtype=dtype_val)), \\\n",
    "                                                                              param_grid, scoring=sc) \\\n",
    "                                                                              .fit(X_train, y_train)\n",
    "        \n",
    "                    results_table = pd.DataFrame(models.cv_results_)\n",
    "                    # results_table.to_excel(file_path + r'\\OvO and OvR\\Output datasets\\gridsearchcv'\n",
    "                                           # + r'\\\\' + file_name\n",
    "                    results_table.to_excel(file_name + '.tsv'\n",
    "                                           + '-hqc' + f'{nc}'\n",
    "                                           + '-ovo'\n",
    "                                           + '-' + sc\n",
    "                                           + '-gridsearchcv.xlsx')\n",
    "        \n",
    "                    # Get best score on test set\n",
    "                    best_model = models.best_estimator_\n",
    "        \n",
    "                    if sc=='precision_weighted':\n",
    "                        y_hat = best_model.predict(X_test)\n",
    "                        best_score = metrics.precision_score(y_test, y_hat, average='weighted')\n",
    "                    if sc=='recall_weighted':\n",
    "                        y_hat = best_model.predict(X_test)\n",
    "                        best_score = metrics.recall_score(y_test, y_hat, average='weighted')\n",
    "                    if sc=='balanced_accuracy':\n",
    "                        y_hat = best_model.predict(X_test)\n",
    "                        best_score = metrics.balanced_accuracy_score(y_test, y_hat)\n",
    "                    if sc=='f1_weighted':\n",
    "                        y_hat = best_model.predict(X_test)\n",
    "                        best_score = metrics.f1_score(y_test, y_hat, average='weighted')\n",
    "                    # if sc=='roc_auc_ovr_weighted':\n",
    "                        # y_score = best_model.predict_proba(X_test)   \n",
    "                        # best_score = metrics.roc_auc_score(y_test, y_score, average='weighted', multi_class='ovr')\n",
    "                    # if sc=='roc_auc_ovo_weighted':\n",
    "                        # y_score = best_model.predict_proba(X_test)\n",
    "                        # best_score = metrics.roc_auc_score(y_test, y_score, average='weighted', multi_class='ovo')\n",
    "            \n",
    "                    # Get best std. dev. on validation set\n",
    "                    best_std_dev = models.cv_results_['std_test_score'][models.best_index_]\n",
    "        \n",
    "                    best_score_std_dev[i] = format(best_score, '.3f') + ' ± ' + format(best_std_dev, '.3f')\n",
    "                else:\n",
    "                    best_score_std_dev[i] = '-'\n",
    "        \n",
    "            best_score_std_dev_n_copies_ovo[k,:] = best_score_std_dev.reshape(1,-1)\n",
    "    \n",
    "        best_score_std_dev_n_copies_ovr_ovo = np.concatenate([best_score_std_dev_n_copies_ovr, \n",
    "                                                              best_score_std_dev_n_copies_ovo], axis=0)\n",
    "\n",
    "        index_names = [f'Helstrom Quantum Centroid {s} (OvR)' for s in n_copies_val]\n",
    "        index_names_ovo = [f'Helstrom Quantum Centroid {t} (OvO)' for t in n_copies_val]\n",
    "        index_names.extend(index_names_ovo)\n",
    "\n",
    "        columns_names = ['Precision (Weighted)',\n",
    "                         'Recall (Weighted)',\n",
    "                         'Balanced Accuracy',\n",
    "                         'F-measure (Weighted)',\n",
    "                         'AUROC - OvR (Weighted)',\n",
    "                         'AUROC - OvO (Weighted)']\n",
    "\n",
    "        df = pd.DataFrame(best_score_std_dev_n_copies_ovr_ovo, index=index_names, columns=columns_names)\n",
    "        # df.to_excel(file_path + r'\\OvO and OvR\\Output datasets' \n",
    "                    # + r'\\\\' + file_name + '-' + str(n_copies_val) + '-results.xlsx')\n",
    "        df.to_excel(file_name + '.tsv' + '-' + strat + '-' + str(n_copies_val) + '-results.xlsx')\n",
    "        \n",
    "    if strat == 'ovr':\n",
    "        # Initialize array containing strings with 13 characters or less\n",
    "        best_score_std_dev_n_copies_ovr = np.empty((len(n_copies_val), len(scores_all)), dtype='<U13')\n",
    "\n",
    "        for j, nc in enumerate(n_copies_val):\n",
    "            # Initialize array containing strings with 13 characters or less\n",
    "            best_score_std_dev = np.empty(len(scores_all), dtype='<U13')\n",
    "\n",
    "            for i, sc in enumerate(scores_all):\n",
    "                # Fitting model, using GridSearchCV with default 5 folds and default stratified sampling\n",
    "                # models = GridSearchCV(OneVsRestClassifier(PGMHQC_gpu_dtype(n_copies=nc, measure='hels', n_jobs=n_jobs_val, \\\n",
    "                                                                           # n_splits=n_splits_val)), param_grid, scoring=sc) \\\n",
    "                models = GridSearchCV(OneVsRestClassifier(PGMHQC_gpu_dtype(n_copies=nc, measure='hels', \\\n",
    "                                                                           n_splits=n_splits_val, dtype=dtype_val)), \\\n",
    "                                                                           param_grid, scoring=sc) \\\n",
    "                                                                           .fit(X_train, y_train)\n",
    "                \n",
    "                results_table = pd.DataFrame(models.cv_results_)\n",
    "                # results_table.to_excel(file_path + r'\\OvO and OvR\\Output datasets\\gridsearchcv'\n",
    "                                       # + r'\\\\' + file_name\n",
    "                results_table.to_excel(file_name + '.tsv'\n",
    "                                       + '-hqc' + f'{nc}'\n",
    "                                       + '-ovr'\n",
    "                                       + '-' + sc\n",
    "                                       + '-gridsearchcv.xlsx')\n",
    "                \n",
    "                # Get best score on test set\n",
    "                best_model = models.best_estimator_\n",
    "                \n",
    "                if sc=='precision_weighted':\n",
    "                    y_hat = best_model.predict(X_test)\n",
    "                    best_score = metrics.precision_score(y_test, y_hat, average='weighted')\n",
    "                if sc=='recall_weighted':\n",
    "                    y_hat = best_model.predict(X_test)\n",
    "                    best_score = metrics.recall_score(y_test, y_hat, average='weighted')\n",
    "                if sc=='balanced_accuracy':\n",
    "                    y_hat = best_model.predict(X_test)\n",
    "                    best_score = metrics.balanced_accuracy_score(y_test, y_hat)\n",
    "                if sc=='f1_weighted':\n",
    "                    y_hat = best_model.predict(X_test)\n",
    "                    best_score = metrics.f1_score(y_test, y_hat, average='weighted')\n",
    "                if sc=='roc_auc_ovr_weighted':\n",
    "                    y_score = best_model.predict_proba(X_test)\n",
    "                    best_score = metrics.roc_auc_score(y_test, y_score, average='weighted', multi_class='ovr')\n",
    "                if sc=='roc_auc_ovo_weighted':\n",
    "                    y_score = best_model.predict_proba(X_test)\n",
    "                    best_score = metrics.roc_auc_score(y_test, y_score, average='weighted', multi_class='ovo')\n",
    "                    \n",
    "                # Get best std. dev. on validation set\n",
    "                best_std_dev = models.cv_results_['std_test_score'][models.best_index_]\n",
    "                          \n",
    "                best_score_std_dev[i] = format(best_score, '.3f') + ' ± ' + format(best_std_dev, '.3f')\n",
    "    \n",
    "            best_score_std_dev_n_copies_ovr[j,:] = best_score_std_dev.reshape(1,-1)\n",
    "        \n",
    "        index_names = [f'Helstrom Quantum Centroid {s} (OvR)' for s in n_copies_val]\n",
    "        \n",
    "        columns_names = ['Precision (Weighted)',\n",
    "                         'Recall (Weighted)',\n",
    "                         'Balanced Accuracy',\n",
    "                         'F-measure (Weighted)',\n",
    "                         'AUROC - OvR (Weighted)',\n",
    "                         'AUROC - OvO (Weighted)']\n",
    "        \n",
    "        df = pd.DataFrame(best_score_std_dev_n_copies_ovr, index=index_names, columns=columns_names)\n",
    "        # df.to_excel(file_path + r'\\OvO and OvR\\Output datasets' \n",
    "                    # + r'\\\\' + file_name + '-' + str(n_copies_val) + '-results.xlsx')\n",
    "        df.to_excel(file_name + '.tsv' + '-' + strat + '-' + str(n_copies_val) + '-results.xlsx')    \n",
    "        \n",
    "    if strat == 'ovo':\n",
    "        # Initialize array containing strings with 13 characters or less\n",
    "        best_score_std_dev_n_copies_ovo = np.empty((len(n_copies_val), len(scores_all)), dtype='<U13')\n",
    "        \n",
    "        for k, nc in enumerate(n_copies_val):\n",
    "            # Initialize array containing strings with 13 characters or less\n",
    "            best_score_std_dev = np.empty(len(scores_all), dtype='<U13')\n",
    "                              \n",
    "            for i, sc in enumerate(scores_all):\n",
    "                # OneVsOneClassifier does not have roc_auc\n",
    "                if sc not in ['roc_auc_ovr_weighted', 'roc_auc_ovo_weighted']:\n",
    "                    # Fitting model, using GridSearchCV with default 5 folds and default stratified sampling\n",
    "                    # models = GridSearchCV(OneVsOneClassifier(PGMHQC_gpu_dtype(n_copies=nc, measure='hels', n_jobs=n_jobs_val, \\\n",
    "                                                                              # n_splits=n_splits_val)), param_grid, scoring=sc) \\\n",
    "                    models = GridSearchCV(OneVsOneClassifier(PGMHQC_gpu_dtype(n_copies=nc, measure='hels', \\\n",
    "                                                                              n_splits=n_splits_val, dtype=dtype_val)), \\\n",
    "                                                                              param_grid, scoring=sc) \\\n",
    "                                                                              .fit(X_train, y_train)\n",
    "\n",
    "                    results_table = pd.DataFrame(models.cv_results_)\n",
    "                    # results_table.to_excel(file_path + r'\\OvO and OvR\\Output datasets\\gridsearchcv'\n",
    "                                           # + r'\\\\' + file_name\n",
    "                    results_table.to_excel(file_name + '.tsv'\n",
    "                                           + '-hqc' + f'{nc}'\n",
    "                                           + '-ovo'\n",
    "                                           + '-' + sc\n",
    "                                           + '-gridsearchcv.xlsx')\n",
    "        \n",
    "                    # Get best score on test set\n",
    "                    best_model = models.best_estimator_\n",
    "                \n",
    "                    if sc=='precision_weighted':\n",
    "                        y_hat = best_model.predict(X_test)\n",
    "                        best_score = metrics.precision_score(y_test, y_hat, average='weighted')\n",
    "                    if sc=='recall_weighted':\n",
    "                        y_hat = best_model.predict(X_test)\n",
    "                        best_score = metrics.recall_score(y_test, y_hat, average='weighted')\n",
    "                    if sc=='balanced_accuracy':\n",
    "                        y_hat = best_model.predict(X_test)\n",
    "                        best_score = metrics.balanced_accuracy_score(y_test, y_hat)\n",
    "                    if sc=='f1_weighted':\n",
    "                        y_hat = best_model.predict(X_test)\n",
    "                        best_score = metrics.f1_score(y_test, y_hat, average='weighted')\n",
    "                    # if sc=='roc_auc_ovr_weighted':\n",
    "                        # y_score = best_model.predict_proba(X_test)   \n",
    "                        # best_score = metrics.roc_auc_score(y_test, y_score, average='weighted', multi_class='ovr')\n",
    "                    # if sc=='roc_auc_ovo_weighted':\n",
    "                        # y_score = best_model.predict_proba(X_test)\n",
    "                        # best_score = metrics.roc_auc_score(y_test, y_score, average='weighted', multi_class='ovo')\n",
    "                        \n",
    "                    # Get best std. dev. on validation set\n",
    "                    best_std_dev = models.cv_results_['std_test_score'][models.best_index_]\n",
    "        \n",
    "                    best_score_std_dev[i] = format(best_score, '.3f') + ' ± ' + format(best_std_dev, '.3f')\n",
    "                else:\n",
    "                    best_score_std_dev[i] = '-'\n",
    "                    \n",
    "            best_score_std_dev_n_copies_ovo[k,:] = best_score_std_dev.reshape(1,-1)\n",
    "            \n",
    "        index_names_ovo = [f'Helstrom Quantum Centroid {t} (OvO)' for t in n_copies_val]\n",
    "        \n",
    "        columns_names = ['Precision (Weighted)',\n",
    "                         'Recall (Weighted)',\n",
    "                         'Balanced Accuracy',\n",
    "                         'F-measure (Weighted)',\n",
    "                         'AUROC - OvR (Weighted)',\n",
    "                         'AUROC - OvO (Weighted)']\n",
    "        \n",
    "        df = pd.DataFrame(best_score_std_dev_n_copies_ovo, index=index_names_ovo, columns=columns_names)\n",
    "        # df.to_excel(file_path + r'\\OvO and OvR\\Output datasets' \n",
    "                    # + r'\\\\' + file_name + '-' + str(n_copies_val) + '-results.xlsx')\n",
    "        df.to_excel(file_name + '.tsv' + '-' + strat + '-' + str(n_copies_val) + '-results.xlsx')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_splits_val = as close to 1 as possible\n",
    "hqc_ovr_ovo_gpu_gcp(# file_path = '../input', \n",
    "                     file_name = 'krkopt',\n",
    "                     strat = 'ovr',\n",
    "                     n_copies_val = [4], \n",
    "                     n_splits_val = 1900,\n",
    "                     dtype_val = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
